<div align=center>

# Awesome Token-wise Generation Acceleration

üì¢ Collections of Awesome Token-wise Generation Acceleration Resources.

</div>


## üìö <span id="head1"> *Contents* </span>

- [Token-wise Generation Acceleration](TOKEN-WISE.md)
  - [Image Generation](#image-generation)
  - [Video Generation](#video-generation)


## üí¨ <span id="head1"> *Keywords* </span>
![](https://img.shields.io/badge/Method_Abbreviation-blue) ![](https://img.shields.io/badge/Downstream_Application-green)  ![](https://img.shields.io/badge/W./W.O._Training-brown) ![](https://img.shields.io/badge/Reduction_Criteria-purple) ![](https://img.shields.io/badge/Reduction_Mechanism-orange)


### üñºÔ∏è Image Generation:


- **[1] Token Merging for Fast Stable Diffusion**, CVPRW 2023.
  
  *Bolya, Daniel and Hoffman, Judy.*

  [[Paper](https://arxiv.org/abs/2303.17604)] [[Code](https://github.com/dbolya/tomesd)] ![](https://img.shields.io/badge/ToMe-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Similarity_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[2] Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models**, CVPR 2024.
  
  *Wang, Hongjie and Liu, Difan and Kang, Yan and Li, Yijun and Lin, Zhe and Jha, Niraj K and Liu, Yuchen.*

  [[Paper](https://arxiv.org/abs/2405.05252)] [Code] ![](https://img.shields.io/badge/AT_EDM-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[3] Token Fusion: Bridging the Gap between Token Pruning and Token Merging**, WACV 2024.
  
  *Kim, Minchul and Gao, Shangqian and Hsu, Yen-Chang and Shen, Yilin and Jin, Hongxia.*

  [[Paper](https://arxiv.org/abs/2312.01026)] [Code] ![](https://img.shields.io/badge/ToFu-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Similarity_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[4] ToDo: Token Downsampling for Efficient Generation of High-Resolution Images**, IJCAIw 2024.
  
  *Smith, Ethan and Saxena, Nayan and Saha, Aninda.*

  [[Paper](https://arxiv.org/abs/2402.13573)] [[Code](https://github.com/ethansmith2000/ImprovedTokenMerge)] ![](https://img.shields.io/badge/ToDo-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Similarity_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[5] Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Models**, ECCV 2024.
  
  *Ju, Chen and Wang, Haicheng and Li, Zeqian and Chen, Xu and Zhai, Zhonghua and Huang, Weilin and Xiao, Shuai.*

  [[Paper](https://arxiv.org/abs/2407.11717)] [Code] ![](https://img.shields.io/badge/Turbo-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[6] Agent Attention: On the Integration of Softmax and Linear Attention**, ECCV 2024.
  
  *Han, Dongchen and Ye, Tianzhu and Han, Yizeng and Xia, Zhuofan and Song, Shiji and Huang, Gao.*
  
  [[Paper](https://arxiv.org/abs/2312.01026)] [[Code](https://github.com/LeapLabTHU/Agent-Attention)] ![](https://img.shields.io/badge/Agent_Attention-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Linear_Attention-orange)

- **[7] Token Caching for Diffusion Transformer Acceleration**, arXiv 2024.

  *Jinming Lou and Wenyang Luo and Yufan Liu and Bing Li and Xinmiao Ding and Weiming Hu and Jiajiong Cao and Yuming Li and Chenguang Ma.*

  [[Paper](https://arxiv.org/abs/2409.18523)] [Code] ![](https://img.shields.io/badge/TokenCache-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[8] Dynamic Diffusion Transformer**, arXiv 2024.

  *Wangbo Zhao and Yizeng Han and Jiasheng Tang and Kai Wang and Yibing Song and Gao Huang and Fan Wang and Yang You.*

  [[Paper](https://arxiv.org/abs/2410.03456)] [[Code](https://github.com/NUS-HPC-AI-Lab/Dynamic-Diffusion-Transformer)] ![](https://img.shields.io/badge/DyDiT-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[9] Accelerating Diffusion Transformers with Token-wise Feature Caching**, arXiv 2024.

  *Chang Zou and Xuyang Liu and Ting Liu and Siteng Huang and Linfeng Zhang.*
  
  [[Paper](https://arxiv.org/abs/2410.05317)] [[Code](https://github.com/Shenyi-Z/ToCa)] ![](https://img.shields.io/badge/ToCa-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Text2Video-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Caching-orange)

- **[10] Importance-based Token Merging for Diffusion Models**, arXiv 2024.

  *Wu, Haoyu and Xu, Jingyi and Le, Hieu and Samaras, Dimitris.*

  [[Paper](https://arxiv.org/abs/2411.16720)] [Code] ![](https://img.shields.io/badge/IToMe-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Importance_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[11] FlexDiT: Dynamic Token Density Control for Diffusion Transformer**, arXiv 2024.

  *Shuning Chang and Pichao Wang and Jiasheng Tang and Yi Yang.*
  
  [[Paper](https://arxiv.org/abs/2412.06028)] [[Code](https://github.com/changsn/FlexDiT)] ![](https://img.shields.io/badge/FlexDiT-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Text2Video-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pruning-orange)


- **[12] CAT Pruning: Cluster-Aware Token Pruning For Text-to-Image Diffusion Models**, NeurIPSw 2024.
  
  *Xinle Cheng, Zhuoming Chen, Zhihao Jia.*
  
  [[Paper](https://openreview.net/pdf/bf470617f541635cbde87fcc0ba3fdbddcef3db7.pdf)] [[Code](https://github.com/ada-cheng/CAT-Pruning)] ![](https://img.shields.io/badge/CAT_Pruning-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Clustering_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[13] ToMA: Token Merging with Attention For Diffusion Models**, OpenReview 2024.
  
  [[Paper](https://openreview.net/forum?id=xhtqgW5b93)] [[Code](https://openreview.net/forum?id=xhtqgW5b93)] ![](https://img.shields.io/badge/ToMA-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[14] Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis**, NeurIPS 2024.

  *Taihang Hu and Linxuan Li and Joost van de Weijer and Hongcheng Gao and Fahad Khan and Jian Yang and Ming-Ming Cheng and Kai Wang and Yaxing Wang.*

  [[Paper](https://arxiv.org/abs/2411.07132)] [[Code](https://github.com/hutaiHang/ToMe)] ![](https://img.shields.io/badge/ToMe-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Semantic_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[15] Layer- and Timestep-Adaptive Differentiable Token Compression Ratios for Efficient Diffusion Transformers**, arXiv 2024.

  *Haoran You and Connelly Barnes and Yuqian Zhou and Yan Kang and Zhenbang Du and Wei Zhou and Lingzhi Zhang and Yotam Nitzan and Xiaoyang Liu and Zhe Lin and Eli Shechtman and Sohrab Amirghodsi and Yingyan Celine Lin.*
  
   [[Paper](https://arxiv.org/abs/2412.16822)] [[Code](https://github.com/GATECH-EIC/DiffRatio-MoD)] ![](https://img.shields.io/badge/DiffRatio_MoD-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[16] Multistage Compression Optimization Strategies for Accelerating Diffusion Models**, PRCV 2024.

  *Huang, Weiquan and Chen, Qiang.*
  
  [[Paper](https://link.springer.com/chapter/10.1007/978-981-97-8487-5_16)] [Code] ![](https://img.shields.io/badge/MCO-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Compression-orange)

- **[17] ImageFolder: Autoregressive Image Generation with Folded Tokens**, arXiv 2024.

  *Li, Xiang and Qiu, Kai and Chen, Hao and Kuen, Jason and Gu, Jiuxiang and Raj, Bhiksha and Lin, Zhe.*
  
  [[Paper](https://arxiv.org/abs/2410.01756)] [Code] ![](https://img.shields.io/badge/ImageFolder-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Folding-orange)

- **[18] Training-Free and Hardware-Friendly Acceleration for Diffusion Models via Similarity-based Token Pruning**, arXiv 2024.

  *Zhang, Evelyn and Tang, Jiayi and Ning, Xuefei and Zhang, Linfeng.*
  
  [[Paper](https://www.researchgate.net/profile/Linfeng-Zhang-18/publication/387204421_Training-Free_and_Hardware-Friendly_Acceleration_for_Diffusion_Models_via_Similarity-based_Token_Pruning/links/6763f5c78cfcdf077fe561e0/Training-Free-and-Hardware-Friendly-Acceleration-for-Diffusion-Models-via-Similarity-based-Token-Pruning.pdf)] [Code] ![](https://img.shields.io/badge/SiTo-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Similarity_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[19] An Image is Worth 32 Tokens for Reconstruction and Generation**, arXiv 2024.

  *Yu, Qihang and Weber, Mark and Deng, Xueqing and Shen, Xiaohui and Cremers, Daniel and Chen, Liang-Chieh.*
  
  [[Paper](https://arxiv.org/abs/2406.07550)] [Code] ![](https://img.shields.io/badge/Token32-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Compression-orange)

- **[20] U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers**, arXiv 2024.

  *Tian, Yuchuan and Tu, Zhijun and Chen, Hanting and Hu, Jie and Xu, Chao and Wang, Yunhe.*
  
  [[Paper](https://arxiv.org/abs/2405.02730)] [Code] ![](https://img.shields.io/badge/U_DiTs-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Downsampling-orange)
  
- **[21] Accelerating Text-to-Image Editing via Cache-Enabled Sparse Diffusion Inference**, AAAI 2024.

  *Yu, Zihao and Li, Haoyang and Fu, Fangcheng and Miao, Xupeng and Cui, Bin.*

  [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/29599)] [Code] ![](https://img.shields.io/badge/CESDI-blue) ![](https://img.shields.io/badge/Image_Editing-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Cache_Based-purple) ![](https://img.shields.io/badge/Sparse_Inference-orange)

- **[22] Adaptive Computation Modules: Granular Conditional Computation For Efficient Inference**, arXiv 2023.

  *W√≥jcik, Bartosz and Devoto, Alessio and Pustelnik, Karol and Minervini, Pasquale and Scardapane, Simone.*

  [[Paper](https://arxiv.org/abs/2312.10193)] [Code] ![](https://img.shields.io/badge/ACM-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Conditional_Computation-orange)

- **[23] Highlight Diffusion: Training-Free Attention Guided Acceleration for Text-to-Image Models**, OpenReview 2024.
  
  *Nam, Kyuseok and Kim, Yulhwa and Park, Jeongwoo.*

  [[Paper](https://openreview.net/forum?id=Jt1gGIumJo)] [Code] ![](https://img.shields.io/badge/HighlightDiff-blue) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Selection-orange)

- **[24] Layer- and Timestep-Adaptive Differentiable Token Compression Ratios**, arXiv 2024.
  
  *You, Haoran and Barnes, Connelly and Zhou, Yuqian and others.*

  [[Paper](https://arxiv.org/abs/2412.16822)] [Code] ![](https://img.shields.io/badge/LTA_DiTC-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Compression-orange)

- **[25] Fast Training of Diffusion Models with Masked Transformers**, arXiv 2023.
  
  *Zheng, Hongkai and Nie, Weili and Vahdat, Arash and Anandkumar, Anima.*

  [[Paper](https://arxiv.org/abs/2306.09305)] [Code] ![](https://img.shields.io/badge/MaskDiff-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Masked_Training-orange)

- **[26] MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer**, ICCV 2023.
  
  *Gao, Shanghua and Zhou, Pan and Cheng, Ming-Ming and Yan, Shuicheng.*

  [[Paper](https://arxiv.org/abs/2303.14389)] [Code] ![](https://img.shields.io/badge/MDTv2-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Masked_Training-orange)

- **[27] Diffusion Models as Masked Autoencoders**, ICCV 2023.
  
  *Wei, Chen and Mangalam, Karttikeya and Huang, Po-Yao and others.*

  [[Paper](https://arxiv.org/abs/2304.03283)] [Code] ![](https://img.shields.io/badge/DiffMAE-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Masked_Training-orange)

- **[28] DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers**, arXiv 2024.
  
  *Zhao, Xuanlei and Cheng, Shenggan and Chen, Chang and others.*

  [[Paper](https://arxiv.org/abs/2403.10266)] [Code] ![](https://img.shields.io/badge/DSP-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Sequence_Parallelism-orange)

- **[29] Accelerating Diffusion Transformers with Dual Feature Caching**, arXiv 2024.

  *Chang Zou and Evelyn Zhang and Runlin Guo and Haohang Xu and Conghui He and Xuming Hu and Linfeng Zhang.*
  
  [[Paper](https://arxiv.org/abs/2410.05317)] [[Code](https://github.com/Shenyi-Z/DuCa)] ![](https://img.shields.io/badge/DuCa-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Text2Video-green) ![](https://img.shields.io/badge/Token_Caching-orange) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Caching-orange)

- **[30] Cached Adaptive Token Merging: Dynamic Token Reduction and Redundant Computation Elimination in Diffusion Model**, arXiv 2024.

  *Omid Saghatchian and Atiyeh Gh. Moghadam and Ahmad Nickabadi.*

  [[Paper](https://arxiv.org/abs/2501.00946)] [[Code](https://github.com/omidiu/ca_tome)] ![](https://img.shields.io/badge/DaTo-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Similarity_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange) ![](https://img.shields.io/badge/Token_Caching-orange) 

- **[31] Token Pruning for Caching Better: 9 Times Acceleration on Stable Diffusion for Free**, arXiv 2024.

  *Evelyn Zhang and Bang Xiao and Jiayi Tang and Qianli Ma and Chang Zou and Xuefei Ning and Xuming Hu and Linfeng Zhang.*

  [[Paper](https://arxiv.org/abs/2501.00375)] [[Code](https://github.com/EvelynZhang-epiclab/DaTo)] ![](https://img.shields.io/badge/DaTo-blue) ![](https://img.shields.io/badge/Image_Generation-green) ![](https://img.shields.io/badge/Text2Image-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Similarity_Based-purple)  ![](https://img.shields.io/badge/Token_Pruning-orange) ![](https://img.shields.io/badge/Token_Caching-orange)


### üé• Video Generation:

- **[1] F<sup>3</sup>-Pruning: A Training-Free and Generalized Pruning Strategy towards Faster and Finer Text-to-Video Synthesis**, AAAI 2024.
  
  *Su, Sitong and Liu, Jianzhi and Gao, Lianli and Song, Jingkuan.*

  [[Paper](https://arxiv.org/abs/2312.03459)] [Code] ![](https://img.shields.io/badge/F3_Pruning-blue) ![](https://img.shields.io/badge/Text2Video-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[2] AsymRnR: Video Diffusion Transformers Acceleration with Asymmetric brownuction and Restoration**, arXiv 2024.

  *Wenhao Sun and Rong-Cheng Tu and Jingyi Liao and Zhao Jin and Dacheng Tao.*
  
  [[Paper](https://arxiv.org/abs/2412.11706)] [Code] ![](https://img.shields.io/badge/AsymRnR-blue) ![](https://img.shields.io/badge/Text2Video-green) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[3] Object-Centric Diffusion for Efficient Video Editing**, ECCV 2024.

  *Kahatapitiya, Kumara and Karjauv, Adil and Abati, Davide and Porikli, Fatih and Asano, Yuki M and Habibian, Amirhossein.*
  
  [[Paper](https://arxiv.org/abs/2401.05735)] [Code] ![](https://img.shields.io/badge/OCD-blue) ![](https://img.shields.io/badge/Video_Editing-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Similarity_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[4] DiCoDe: Diffusion-Compressed Deep Tokens for Autoregressive Video Generation with Language Models**, arXiv 2024.
  
  *Li, Yizhuo and Ge, Yuying and Ge, Yixiao and Luo, Ping and Shan, Ying.*

  [[Paper](https://arxiv.org/abs/2412.04446)] [Code] ![](https://img.shields.io/badge/DiCoDe-blue) ![](https://img.shields.io/badge/Video_Generation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Merging-orange)


